{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Neural Data Analysis_\n",
    "\n",
    "Lecturer: Prof. Dr. Philipp Berens, Dr. Alexander Ecker\n",
    "\n",
    "Tutors: Sarah Strauss, Santiago Cadena\n",
    "\n",
    "Summer term 2019\n",
    "\n",
    "Due date: 2019-04-23, 9am\n",
    "\n",
    "Student names: *FILL IN YOUR NAMES HERE*\n",
    "\n",
    "# Exercise sheet 1\n",
    "\n",
    "Download the data file ```nda_ex1.csv``` from ILIAS and save it in a subfolder ```../data/```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy as sp\n",
    "import itertools as it\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 30000     # sampling rate of the signal in Hz\n",
    "dt = 1/Fs\n",
    "gain = .5      # gain of the signal\n",
    "x = pd.read_csv('../data/nda_ex_1.csv', header=0, names=('Ch1', 'Ch2', 'Ch3', 'Ch4'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Filter Signal\n",
    "\n",
    "In order to detect action potentials, the first step is to filter out low frequency fluctuations (LFP) and high frequency noise. Determine appropriate filter settings and implement the filtering in the function ```filterSignal()```. A typical choice for this task would be a butterworth filter. Plot a segment of the raw signal and the filtered signal for all four channels with matching y-axis. The segment you choose should contain spikes. When you apply the function also test different filter settings.\n",
    "\n",
    "*Grading: 2 pts*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterSignal(x, Fs, low, high):\n",
    "# Filter raw signal\n",
    "#   y = filterSignal(x, Fs, low, high) filters the signal x. Each column in x is one\n",
    "#   recording channel. Fs is the sampling frequency. low and high specify the passband in Hz.\n",
    "#   The filter delay is compensated in the output y.\n",
    "\n",
    "        \n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = filterSignal(x, Fs, 500, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "T = 100000\n",
    "t = np.arange(0,T) * dt \n",
    "\n",
    "for i, col in enumerate(xf):\n",
    "    plt.subplot(4,2,2*i+1)\n",
    "    plt.plot(t,x[col][0:T],linewidth=.5)\n",
    "    plt.ylim((-1000, 1000))\n",
    "    plt.xlim((0,3))\n",
    "    plt.ylabel('Voltage')\n",
    "    \n",
    "    \n",
    "    plt.subplot(4,2,2*i+2)\n",
    "    plt.plot(t,xf[col][0:T],linewidth=.5)\n",
    "    plt.ylim((-400, 250))\n",
    "    plt.xlim((0,3))\n",
    "    plt.ylabel('Voltage')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Detect action potentials\n",
    "\n",
    "Action potentials are usually detected by finding large-amplitude deflections in the continuous signal. A good choice of threshold for detecting spikes is important. If it is too low, you will detect too many low amplitude events (noise); if it is too high, you run the risk of missing good spikes. Implement an automatic procedure to obtain a reasonable threshold and detect the times when spikes occurred in the function ```detectSpikes()``` . Plot a segment of the filtered signal for all four channels with matching y-axis and indicate the time points where you detected spikes. Plot the threshold. Are the detected time points well aligned with peaks in the signal?\n",
    "\n",
    "*Grading: 3 pts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSpikes(x,Fs):\n",
    "# Detect spikes\n",
    "# s, t = detectSpikes(x,Fs) detects spikes in x, where Fs the sampling\n",
    "#   rate (in Hz). The outputs s and t are column vectors of spike times in\n",
    "#   samples and ms, respectively. By convention the time of the zeroth\n",
    "#   sample is 0 ms.\n",
    "\n",
    "\n",
    "\n",
    "    return (s, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = xf.shape[0]\n",
    "s, t = detectSpikes(xf.as_matrix(),Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 8))\n",
    "\n",
    "tt = np.arange(0,T) * dt \n",
    "\n",
    "for i, col in enumerate(xf):\n",
    "    plt.subplot(4,1,i+1)\n",
    "    plt.plot(tt,xf[col],linewidth=.5)\n",
    "    plt.plot(tt[s],xf[col][s],'r.')\n",
    "    plt.ylim((-400, 400))\n",
    "    plt.xlim((0.025,0.075))\n",
    "    plt.ylabel('Voltage')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Extract waveforms\n",
    "For later spike sorting we need the waveforms of all detected spikes. Extract the waveforms segments (1 ms) on all four channels for each spike time (as a result each spike is represented by a 4x30 element matrix). Implement this procedure in the function ```extractWaveforms()```. Plot (a) the first 100 spikes you detected and (b) the 100 largest spikes you detected. Are there a lot of very small spikes (likely noise) among your detected spikes? If so your threshold may be too low. Can you see obvious artifacts, not looking like spikes at all?\n",
    "\n",
    "*Grading: 2 pts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWaveforms(x, s):\n",
    "# Extract spike waveforms.\n",
    "#   w = extractWaveforms(x, s) extracts the waveforms at times s (given in\n",
    "#   samples) from the filtered signal x using a fixed window around the\n",
    "#   times of the spikes. The return value w is a 3d array of size\n",
    "#   length(window) x #spikes x #channels.\n",
    "\n",
    "\n",
    "    return w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = extractWaveforms(xf.as_matrix(),s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot first 100 spike waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(-10,20) * dt * 1000 \n",
    "\n",
    "plt.figure(figsize=(11, 8))\n",
    "\n",
    "for i, col in enumerate(xf):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(t,w[:,1:100,i],'k', linewidth=1)\n",
    "    plt.ylim((-500, 250))\n",
    "    plt.xlim((-0.33,0.66))\n",
    "    plt.ylabel('Voltage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot largest 100 spike waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(np.min(np.min(w,axis=2),axis=0))\n",
    "\n",
    "\n",
    "t = np.arange(-10,20) * dt * 1000 \n",
    "\n",
    "plt.figure(figsize=(11, 8))\n",
    "for i, col in enumerate(xf):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(t,w[:,idx[0:100],i],'k', linewidth=1)\n",
    "    plt.ylim((-1000, 500))\n",
    "    plt.xlim((-0.33,0.66))\n",
    "    plt.ylabel('Voltage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Extract features using PCA\n",
    "Compute the first three PCA features on each channel separately in ```extractFeatures()```. You can use a available PCA implementation or implement it yourself. After that, each spike is represented by a 12 element vector. Compute the fraction of variance captured by these three PCs.\n",
    "Plot scatter plots for all pairwise combinations of 1st PCs. Do you see clusters visually? \n",
    "\n",
    "*Grading: 2+1 pts*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractFeatures(w):\n",
    "# Extract features for spike sorting.\n",
    "#   b = extractFeatures(w) extracts features for spike sorting from the\n",
    "#   waveforms in w, which is a 3d array of size length(window) x #spikes x\n",
    "#   #channels. The output b is a matrix of size #spikes x #features.\n",
    "#   The implementation should do PCA on the waveforms of each channel\n",
    "#   separately and uses the first three principal components. Thus, we get\n",
    "#   a total of 12 features. Also, the varianced explained by the 3 features per channel\n",
    "#   should be computed.\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    return b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = extractFeatures(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.suptitle('Scatter plots',fontsize=20)\n",
    "\n",
    "idx = [0, 3, 6, 9]\n",
    "p = 1\n",
    "labels = ['Ch1','Ch2','Ch3','Ch4']\n",
    "for i in np.arange(0,4):\n",
    "    for j in np.arange(i+1,4):\n",
    "        ax = plt.subplot(2,3,p, aspect='equal')\n",
    "        plt.plot(b[:,idx[i]],b[:,idx[j]],'.k', markersize=.7) \n",
    "        plt.xlabel(labels[i])\n",
    "        plt.ylabel(labels[j])\n",
    "        plt.xlim((-1500,1500))\n",
    "        plt.ylim((-1500,1500))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        p = p+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/nda_ex_1_features',b)\n",
    "np.save('../data/nda_ex_1_spiketimes',s)\n",
    "np.save('../data/nda_ex_1_waveforms',w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def mog_old(x, k, m, S, p, y, ind, arr):\n",
    "# Fit Mixture of Gaussian model\n",
    "#   ind, m, S, p = mog(x,k) fits a Mixture of Gaussian model to the data in\n",
    "#   x using k components. The output ind contains the MAP assignments of the\n",
    "#   datapoints in x to the found clusters. The outputs m, S, p contain\n",
    "#   the model parameters.\n",
    "#\n",
    "#   x:     N by D\n",
    "#\n",
    "#   ind:   N by 1\n",
    "#   m:     k by D\n",
    "#   S:     D by D by k\n",
    "#   p:     k by 1\n",
    "\n",
    "    # fill in your code here\n",
    "            \n",
    "    iteration = 100;\n",
    "    iter_count = 0;\n",
    "    \n",
    "    threshold = 1e-30\n",
    "    log_likelihood_old = 0;\n",
    "    log_likelihood_new = 1;\n",
    "    \n",
    "    while iter_count < iteration and np.abs(log_likelihood_old - log_likelihood_new) > threshold:\n",
    "              \n",
    "        for j in range(N):           \n",
    "            sum_tmp = 0;\n",
    "            for i in range(k): \n",
    "                minus = x[j] - m[i];\n",
    "                \n",
    "                matmul_1 = (minus[0] * S[1][1][i] + minus[1] * (-1*S[0][1][i])) / np.linalg.det(S[:, :, i]);\n",
    "                matmul_2 = (minus[0] * (-1*S[1][0][i]) + minus[1] * S[0][0][i]) / np.linalg.det(S[:, :, i]);\n",
    "                \n",
    "                matmul_tmp = matmul_1 * minus[0] + matmul_2 * minus[1];     \n",
    "                                \n",
    "                exp_tmp = np.exp(-0.5 * matmul_tmp);\n",
    "                posterior = (p[i] / (2 * math.pi * np.sqrt(np.linalg.det(S[:, :, i])))) * exp_tmp;\n",
    "                sum_tmp += posterior;\n",
    "                y[j][i] = posterior;\n",
    "                \n",
    "            for i in range(k):\n",
    "                y[j][i] = y[j][i] /sum_tmp;   \n",
    "\n",
    "        N_k = np.zeros(k);\n",
    "        \n",
    "        for i in range(k):\n",
    "            for j in range(N):\n",
    "                N_k[i] += y[j][i];\n",
    "                \n",
    "        p[0] = N_k[0] / N;\n",
    "        p[1] = N_k[1] / N;\n",
    "        p[2] = N_k[2] / N;\n",
    "                \n",
    "        for i in range(k):      \n",
    "            sum_tmp_x = 0;     \n",
    "            sum_tmp_y = 0;\n",
    "            \n",
    "            for j in range(N):               \n",
    "                sum_tmp_x += y[j][i] * x[j][0]; \n",
    "                sum_tmp_y += y[j][i] * x[j][1];    \n",
    "            \n",
    "            m[i][0] = sum_tmp_x/N_k[i];\n",
    "            m[i][1] = sum_tmp_y/N_k[i];\n",
    "                                 \n",
    "            sum_tmp_11 = 0;     \n",
    "            sum_tmp_12 = 0;   \n",
    "            sum_tmp_21 = 0;     \n",
    "            sum_tmp_22 = 0;\n",
    "            \n",
    "            for j in range(N):      \n",
    "                \n",
    "                tmp_arr = x[j] - m[i];  \n",
    "                \n",
    "                sum_tmp_11 += y[j][i] * (tmp_arr[0]*tmp_arr[0]);\n",
    "                sum_tmp_12 += y[j][i] * (tmp_arr[0]*tmp_arr[1]);\n",
    "                sum_tmp_21 += y[j][i] * (tmp_arr[0]*tmp_arr[1]);\n",
    "                sum_tmp_22 += y[j][i] * (tmp_arr[1]*tmp_arr[1]);\n",
    "                   \n",
    "            S[0, 0, i] = sum_tmp_11/N_k[i];\n",
    "            S[0, 1, i] = sum_tmp_12/N_k[i];\n",
    "            \n",
    "            S[1, 0, i] = sum_tmp_21/N_k[i];\n",
    "            S[1, 1, i] = sum_tmp_22/N_k[i];\n",
    "\n",
    "        iter_count += 1; \n",
    "        \n",
    "        log_likelihood_old = log_likelihood_new;        \n",
    "        log_likelihood_new = 0;\n",
    "        \n",
    "        for j in range(N): \n",
    "            \n",
    "            log_sum = 0;\n",
    "            \n",
    "            for i in range(k):\n",
    "                minus = x[j] - m[i];\n",
    "                \n",
    "                matmul_1 = (minus[0] * S[1][1][i] + minus[1] * (-1*S[0][1][i])) / np.linalg.det(S[:, :, i]);\n",
    "                matmul_2 = (minus[0] * (-1*S[1][0][i]) + minus[1] * S[0][0][i]) / np.linalg.det(S[:, :, i]);\n",
    "                \n",
    "                matmul_tmp = matmul_1 * minus[0] + matmul_2 * minus[1];     \n",
    "                \n",
    "                exp_tmp = np.exp(-0.5 * matmul_tmp);\n",
    "                posterior = (p[i] / (2 * math.pi * np.sqrt(np.linalg.det(S[:, :, i])))) * exp_tmp;\n",
    "                \n",
    "                log_sum += math.log(posterior);\n",
    "                \n",
    "            log_likelihood_new += log_sum;\n",
    "            \n",
    "    for j in range(N): \n",
    "        for i in range(k):\n",
    "            arr[i] = y[j][i];\n",
    "        ind[j] = np.argmax(arr);\n",
    "            \n",
    "    return (ind, m, S, p)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
